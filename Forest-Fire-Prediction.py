# -*- coding: utf-8 -*-
"""2014459_notebook .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uvqXY5ZMPu49T-eC9IBaSg_ZJBQABemO


*Project Name*: **Analysing forest fires within a region in Algeria**

# **1. Introduction**

Forest fires are uncontrollable fires that burn in the wildland vegetation. Whilst many of these fires are caused by humans, the data provided for the region of Algeria highlights a concerning change in climate factors, which have thus contributed to the number of forest fires in the area.

*Problems*

The dataset provided has outlined various issues, mainly how frequent forest fires are in Algeria. This is a catastrophic problem due to the verosity of forest fires in general; they are responsible for the loss of life, and terrible damage to the environment. Not only this, but, there is potential for these fires to cause property damages and many other damages, which is why if the forest fire isnt initially prevented, it could snowball and cause a dramatic effect. This is why data science in this area is so important, because it allows us to predict potential future forest fires based on our previous data, which means we would be able to prevent them in advance to minimise the damages.

Based on various data analytics online, forest fires accounted for over $11.2 billion in damage across the United States alone, which makes it even more critical to be able to prevent them.

*Aims:*

The main aim of my data science analysis is to be able to predict forest fires based on the data. This is an area of high importance as it would allow us to deploy sufficient countermeasures to counteract a fire much sooner than regular responses. Although it is nearly impossible  to accurately predict the location and cause of a fire, I believe we would be able to plan and prepare for the danger before it occurs, meaning we would save the environment, wildlife, and even lives if sufficient machine learning prediction techniques are in place.

The models I will be using are aimed to find patterns in the data, thus helping us to predict a forest fire. I plan on using regression and classification models to be able to predict the occurence of a forest fire, as well as finding the similarities between the features. I will be taking many factors of the dataset into account, such as the temperature, in order to aid with this task.

Following this, since I will be discovering patterns in the data, it allows me to accurately identify the cause of the forest fires. I will be looking for the quantifiers to make a relatively accurate assumption regarding what the main cause of the fires are.

Ideally, if our predictions are accurate enough, the data gathered can be given to fire responders in order to help fight the fires. Ideally, more in depth data, such as the size of the fire,  would also allow the analysis of the impact of the forest fire. The models produced could be used to help provide better strategy in regards to fighting fires in the future, as we could be able to determine factors such as how fast the fire spreads based on wind, temperature, the density of the forest, etc.  

*Solution*

So, in order to reach a solution, I have implemented various data science techniques and models in order to be able to predict the occurence of a forest fire based on patterns and similarities in the data, by fitting the data into models, thus providing an insight into what the main features are when it comes to predicting a forest fire. To reach this solution, I need to analyse the data, and then train the models on the specific points of interest, gathering the accuracies of the models used to prove their effectiveness.

I will firstly be analysing the data. I will be looking at:


*   How many fires are present in the data
*   The feature distribution and correlation (to determine the important features)
*   The impact of the main features on the occurence of fires
*   How the temperature has impacted the occurence of a fire

After my data analysis, I will be implementing models such as:

*   The Linear Regression model to discover the correlation between the main features and the Fire Weather Index (Since it was created to be an accurate predictor of a Forest Fire)
*   The Logistic Regression model to discover the correlation between the main features and the target index
*   The Decision Tree Classifier model to see if there will be a stronger correlation using this model

I will be comparing their models to deem which is most effective for this scenario.
"""

#@title Imports

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.cm as cm

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, r2_score
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score

from google.colab import data_table
data_table.enable_dataframe_formatter()

my_palette = ["#50C878", "#CF1920"]
sns.set_palette(my_palette)

"""# **2. Data Description and Exploratory Analysis**

The dataset I am looking at involves multiple factors that are potential contenders for the occurence of a forest fire.

Thankfully, the dataset provided allows us to train models to predict the occurence of forest fires. Depending on the accuracy of the predictions, it could allow us to predict the likelihood of forest fires in the future based on several environmental factors, which has the potential to prevent fires before they occur, unless the occurence is man-made or due to lightning.

I have labelled the dataset based on the variables provided, but more specifically, the composition of the data consists of:

*   Day & Month - Day of the month, and month of the year. The data was recorded from June until september due to the summer heat
*   Temperature - The max temperature in celcius, the higher the temperature, the more suitable the environment for a fire
*   Relative Humidity (RH) - Percentage of the humidity on that given day
*   Wind Speed (WS) - The speed of the wind km/h, this could correlate to the speed of the spread of a fire
*   Rain - The total rain from that day in mm. More rain could possibly aid in fire prevention
*   Fire Weather Index (FWI) - an index that indicates the fire intensity by combining the rate of fire spread with the amount of fuel being consumed.
*   Fine Fuel Moisture Code (FFMC) - This is a numeric rating that indicates the flammability of fine fuel and relative ease of ignition.
*   Duff Moisture Code (DMC) - is used to indicate the moisture content of  organic layers in the environment.
*   Initial Spread Index (ISI) - This is used to indicate the expected rate of fire spread, by combining the FFMC and wind speed.
*   Buildup Index (BUI) - this is a numeric rating of the total amount of fuel that is available for combustion.
*   Target - Two classes, "fire", or "not fire", to whether or not there was a fire

##**Data Pre-processing**

Firstly, I carried out some processing on the data. The data is loaded in and given column labels, before being displayed.
"""

#@title Importing the data set
df = pd.read_csv("ForestFire.csv")
column_labels = ["Day", "Month", "Temp", "RH", "Ws", "Rain",
                 "FFMC", "DMC", "DC", "ISI", "BUI", "FWI",
                 "Target"]
df.columns = column_labels
df.head()

"""Just from the initial view, it is evident that, with some basic filtering, there are some key features that contribute to forest fires based on the dataset:"""

#@title Fires based on FFMC

FFMC_data = df[["FFMC", "Target"]]
FFMC_data_sorted = FFMC_data.sort_values(by="FFMC", ascending=False)
FFMC_data_sorted

#@title Fires based on ISI

ISI_data = df[["ISI", "Target"]]
ISI_data_sorted = ISI_data.sort_values(by="ISI", ascending=False)
ISI_data_sorted

#@title Fires based on FWI

FWI_data = df[["FWI", "Target"]]
FWI_data_sorted = FWI_data.sort_values(by="FWI", ascending=False)
FWI_data_sorted

"""The avenues I have decided to explore for the data are:
*   The FFMC
*   The ISI
*   The FWI
*   The temperature
*   Their correlation with the Target


"""

#@title Counting the amount of fires
df.value_counts("Target")

"""I believe that the best avenues to explore are those which allow us to predict forest fires. In my analysis, I will be trying to discover which features of the data correlate the most with forest fires; thus allowing me to find correlations in the data that can lead to accurate forest fire prediction.

I wanted to initially find the distribution of the dataset. I described the data to view the upper and lower bounds, which, from the results I gathered, made it clear that scaling would need to be done on the future models created, as the variance was very high.
"""

#@title Upper and lower bounds of the data
df.describe()

"""Based on this, I used a boxplot to see the distribution of the features before scaling."""

#@title Distribution of features
plt.figure(figsize=(10, 8))
sns.boxplot(data=df)
plt.title("Distribution of Features")
plt.show()

"""I wanted to delve deeper to be able to find how the features relate to eachother. Since the data presents such high variance based on the boxplot, this raised the question about how scaling the data would have an effect on its accuracy.

 To begin my initial analysis, I used a pie chart to represent the number of forest fires in the data.
"""

#@title Number of forest fires pie chart
number_of_fires = df[df['Target'] == 'fire'].shape[0]
number_of_no_fires = df[df['Target'] == 'notfire'].shape[0]

pie_labels = ['fire', 'notfire']
pie_sizes = [number_of_fires, number_of_no_fires]

piechart, axis = plt.subplots()
axis.pie(pie_sizes, labels=pie_labels, autopct='%1.1f%%', startangle=90)
plt.title("The total amount of forest fires recorded")
plt.show()

"""It is evident here that fires within the timeframe of the data gathered have occured more often than not, which is very concerning.

To expand on this, I wanted to see which month has had the highest number of fires.
"""

#@title Fires per month
plt.figure(figsize=(10, 8))
sns.countplot(data=df, x="Month", hue="Target")
plt.title("Number of forest fires per month")
plt.xticks(np.arange(4), ["June", "July", "August", "September"])
plt.show()

"""It turns out August has a very high number of fires opposed to no fires, which I suspected is due to the temperature rise.

As previously stated, I wanted to examine the impact that the Temperature, FFMC, ISI and FWI have on the occurence a forest fire, so I used a pairplot to represent this and compare them to eachother.
"""

#@title The relation of important features
multiple_features = df[["Temp", "FFMC", "ISI", "FWI", "Target"]]
sns.pairplot(multiple_features, hue="Target")
plt.grid(False)
plt.show()

"""The data presented here is very insightful, as it gives us a general view as to the values to watch out for when fires are most common, more specifically:

*   Temperature - Fires are very scattered, and could occur at any temperature above around 25
*   FFMC - Fires are very common around 82 and higher
*   ISI - Fires are very common around 3 and higher
*   FWI - Fires are very common around 6 and higher

I decided to use a strip plots to investigate this further. I analysed the correlations between the important features and the target to determine which factors are the most responsible.

"""

#@title Fire occurence based on the FFMC, ISI and FWI
figure, axis = plt.subplots(ncols=4, figsize=(22, 8))

sns.stripplot(data=df, x="Month", y="FFMC", hue="Target", ax=axis[0])
axis[0].set_title("The correlation between the FFMC with the Target")

sns.stripplot(data=df, x="Month", y="ISI", hue="Target", ax=axis[1])
axis[1].set_title("The correlation between the ISI with the Target")

sns.stripplot(data=df, x="Month", y="FWI", hue="Target", ax=axis[2])
axis[2].set_title("The correlation between the FWI with the Target")

sns.stripplot(data=df, x="Month", y="Temp", hue="Target", ax=axis[3])
axis[3].set_title("The correlation between the Temperature with the Target")

plt.show()

"""It is evident here that the temperature did not have much of an effect on the occurence of a forest fire. However, the other 3 features did, and they showed that after a specific value, there is always a fire. I wanted to construct my data models on these features as it shows how important they are.

I wanted to expand my analysis by looking at how the temperature relates to the occurence a forest fire. Based off of the previous analysis, I figured it would not have a very strong correlation, but I used a histogram plot to see how the temperatures change per month when there is a forest fire as opposed to when there isnt.
"""

#@title Temperature distribution
plt.figure(figsize=(8, 8))
sns.histplot(data=df, x="Temp", hue="Target")
plt.title('Distribution of Temperature')
plt.show()

"""Not surprisingly, it turns out that the temperatures during the occurence of a forest fires are always upwards of 32 degrees. However, when the temperature reaches 37 degrees, the dataset has shown that there are a frequent amount of fires in this area. However, this isn't the only contributing factor. Despite this, the temperature rise in the areas could be due to the fire itself, so this wouldn't be an accurate prediction method.

I would say that based off this analysis, high temperatures have a reasonable impact on forest fires, and so it would be very hard to predict the occurence of a forest fire based on this feature alone. I wanted to investigate this further to confirm my theory.

However, if my model gives a high accuracy, then it should definitely be a feature that should be recorded in regions of Algeria, because if it is discovered that the temperature of that location is exceeding 37 degrees, then there is definitely a cause for concern and preparation to counter the fires should begin.

Continuing my analysis, I wanted to investigate the correlation between the features. I used a heatmap to display the correlation.

What I discovered was that the DMC, ISI and BUI all have a high correlation to the Fire Wind Index. Additionally, it turns out that the fire wind index has a high correlation with the ISI, and the ISI has a relatively high correlation with the FFMC.

The reason for this is because all of these features contribute to the Fire Weather Index value. the Fire Weather Index gathers these features to estimate the danger of a fire.

More importantly though, the FFMC, ISI and FWI all have above 70% correlation with the target, which are the features that the models will be based on.

This means that these factors are of high importance when examining forest fire data, because when these values are all over 70-80%, the forest fire occurence drastically increases.
"""

#@title Heatmap correlation
heatmap_df = df.drop(columns=['Day', 'Month'])
heatmap_df['Target'] = heatmap_df['Target'].replace({'notfire': 0, 'fire': 1})

fig, ax = plt.subplots(figsize=(12, 8))
sns.heatmap(heatmap_df.corr(), annot=True)
plt.show()

"""The correlation also shows that features such as rain, wind speed and humidity all negatively impact the fire weather index, meaning these features are less likely to contribute to a forest fire.

# **3. Build the Model(s)**

After my initial analysis, it has been revealed that the FWI, the FFMC, the ISI and the temperature are all points of interest that need to be examined. In order to do this, I will be using the following models:


*   Linear regression modelling - This is a regression model that is commonly used as a type of predictive analysis. The aim of a linear regression model is to study how accurately the predictor variables can predict the outcome variable. In my case, since my outcome variable is the fire weather index, I want to see how the core features are related. In other words, it will be used to identify how strongly the environmental conditions associate with the fire weather index

*   Logistic regression modelling - This is a classification model that is used to analyse the effect of the features of the dataset on the target. This will be used as a prediction method, where the dependant variable will be the target, and the independant variables will be the features. Since the target is binary (fire or no fire), logistic regression may be useful here because this type of model can identify the predictors that are most strongly associated with the occurence of a forest fire.

*   Decision tree modelling - This is a classification model in the form of a tree structure. It is used to divide the dataset into smaller subsets while developing the tree. Since decision trees can be used on continuous or categorial data, I will be analysing the effects of features such as the fire weather index and FFMC on the target. The accuracy produced from these models would be useful as, if it is a high accuracy, it would allow us to accurately determine the occurence of a fire based on the variables provided. It would also allow us to see how effective important features such as the fire weather index are on accurately predicting a fire.


I will be scaling the data frame to fit each of the models, and I will compare the accuracy scores before and after the scaling. I will also be comparing the accuracy scores of each model with one another, to guage what the best model to use would be, in order to predict forest fires as accurately as possible.


The questions I gathered from my initial analysis are:

*   How do the environmental features correlate to the Fire Weather Index?
*   How accurately could the temperature change predict a forest fire?
*   How much of an impact do the FFMC, ISI and FWI have on the target outcome?
*   Since the FWI was made specifically to predict a forest fire, how would our accuracy change without it?
*   How does scaling the data effect the models?

For starters, I created a new dataset, dropping the day and month columns. This was so that I had a dataset with predictor variables (such as Temp, FFMC etc..) that I could test on my outcome variables (such as FWI and Target).
"""

#@title Creating the DataFrame
modelled_dataframe = pd.read_csv("ForestFire.csv")
modelled_dataframe.columns = column_labels

df1 = modelled_dataframe.drop(["Day", "Month"], axis=1)
df1['Target'] = df1['Target'].replace({'fire': 1, 'notfire': 0})
df1.head()

"""For each model, a standard scaler is used to transform the data so that the distribution has a mean value of 0, with a standard deviation of 1. The standard scalers purpose is to carry out standardization. Since my dataset has a very large variance (the variables are very different in scale compared to eachother), the scaler will be used to standardize the dataset so that there is a common scale that can be used to train and test the data."""

# Using a standard scaler method for reuse
def standard_scaler(x_train, x_test):
  scaler = StandardScaler()
  x_train_scaled = scaler.fit_transform(x_train)
  x_test_scaled = scaler.transform(x_test)
  return x_train_scaled, x_test_scaled

"""## **Linear Regression Modelling**

In order to answer the question of how the environmental features correlate with the Fire Weather Index, I implemented a linear regression model. The aim of this is to determine the association between the FWI and the independant variables involved. If there is a strong correlation, it suggests that the independant variables are able to accurately predict the fire weather index, which, in this case, would be benficial because it would allow us to accurately calculate the fire weather index before a fire has occured.

It is worth mentioning that linear regression models aren't based solely on accuracy, but I will be testing that regardless to find the correlation.

**Train Test Split**

A train test split involves splitting the data into a training set and a testing set, which is used to train and test the model. In doing so, we can gather an accuracy score on the unseen testing set. The accuracy score can be used to determine the effectiveness of the model used.

"train" in the "train test split" refers to training the model on the training set. What this means is I will be adjusting the parameters of my model in order to minimize the difference between the predicted output, and the actual output.

In this case, I will be creating a dataframe to study the features. I will be analysing the impact of these independant variables on the fire weather index by creating a train test split to split the data into training and test sets.
"""

train_dataframe = df1
x = train_dataframe.drop("FWI", axis=1)
y = train_dataframe["FWI"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=25)

"""**Scaling Features using Standardization**

I now needed to scale the features in my train test split, with the intention of ensuring all features are on the same scale before applying linear regression.
"""

x_train_scaled, x_test_scaled = standard_scaler(x_train, x_test)

"""To compare the difference between the original features and the scaled features, I created 2 boxplots to display the difference."""

#@title Difference between the original and scaled data
fig, (box1, box2) = plt.subplots(ncols=2, figsize=(15, 7))
sns.boxplot(data=x.drop("Target", axis=1), ax=box1)
box1.set_xlabel('Features')
box1.set_title('Original Dataset')
sns.boxplot(data=x_train_scaled, ax=box2)
box2.set_xlabel('Features (Scaled)')
box2.set_title('Scaled Dataset')
plt.show()

"""It is very evident that the plot has been scaled so that all features are on a similar scale, thus allowing them, thus increasing the effectiveness when applying linear regression.

I now wanted to see the how accurate the correlation would be between the features and the target. However, since linear regression is not a classification model, it therefore does not produce categorial predictions, hence why using an r-squared score is more beneficial here, because it measures the proportion of the variance for a dependant variable against the independant variables.

I tested the accuracy score on the data before and after scaling to see the difference in the results.
"""

#@title Calculating the accuracy when applying linear regression
lreg = LinearRegression()
lreg.fit(x_train, y_train)
lreg_pred_unscaled = lreg.predict(x_test)
r2_unscaled = r2_score(y_test, lreg_pred_unscaled)

lreg.fit(x_train_scaled, y_train)
lreg_pred = lreg.predict(x_test_scaled)
r2_scaled = r2_score(y_test, lreg_pred)

print("Accuracy score before scaling: ", r2_unscaled)
print("Accuracy score after scaling: ", r2_scaled)

"""Receiving an r-squared accuracy score of 93.38% using this linear regression model is reasonably good, and so I would suggest that this model could be used to predict the Fire Weather Index in the future, if there is not a model already in place to do so.

I noticed that the accuracy before and after scaling only had minimal differences.

I wanted to see if scaling the data made much difference at all. I decided to create a table to display the differences between the min and max values of each feature.
"""

#@title The differences in each feature
feature_stats = train_dataframe.describe()
print(feature_stats.loc[['min', 'max']])

"""Evidently from the data, it was not the case that scaling is ineffective, because the data before being scaled has a large variance.

In reflection, it may have been more beneficial to use a different scaling technique in order to gather a larger difference in accuracy. However, I decided to plot a linegraph to display the effectiveness of the linear regression model.
"""

#@title Plotting linear regression
fig, ax = plt.subplots()
ax.scatter(y_test, lreg_pred)
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k', lw=1)
ax.set_xlabel('Actual')
ax.set_ylabel('Predicted')
plt.title('Linear Regression')
plt.show()

"""It is evident that the regression model would be used to accurately predict the Fire Weather Index. However, there are a few outliers, especially shown in this graph, which would need to be eliminated to increase the accuracy.

The cause for these outliers could be due to a data collection issue or a measurement error, which could be removed manually or by using the following methods:


*   Z-score method - identifies points that have more than a number of standard deviations from the mean
*   IQR method - using the interquartile range to find the outliers by seeing the difference between the 75th percentile and the 25th percentile of the data
*   Visualisation - Using graphs such as the one above can identify and remove outliers

---

## **Classification Modelling**

I will be using classification models for the rest of the model constructing process. This is because the dependant variable of these models will be the target itself. The target is either "fire" (1) or "notfire" (0). Since the target is binary, classification models will be best suited here because it allows us to predict the occurence or absence of forest fires based on the independant variables.

### *Logistic Regression Modelling*

In order to perform logistic regression, we need to use the target as the output as opposed to the fire wind index, because the output needs to be a value of either 0 or 1.

For my logistic regression model, to answer the question I previously had of how much the FFMC, ISI and FWI have on the target, I have decided to eliminate every other feature when performing my train test split.

**Train Test Split**

Firstly, I create a train-test split on the data. I have allocated 80% for training, and 20% for testing. For each classification model, I have also set the random_state to 25 so that all of the accuracy scores can be compared.
"""

logistic_dataframe = df1.drop(["Temp", "RH", "Ws", "Rain", "DMC", "BUI", "DC"], axis=1)

logistic_x = logistic_dataframe.drop("Target", axis=1)
logistic_y = logistic_dataframe["Target"]
logistic_x_train, logistic_x_test, logistic_y_train, logistic_y_test = train_test_split(logistic_x, logistic_y, test_size=0.2, random_state=25)

"""**Scaling Features**

Again, the features are then scaled so that the logistic regression model can be fitted with a higher accuracy.
"""

logistic_x_train_scaled, logistic_x_test_scaled = standard_scaler(logistic_x_train, logistic_x_test)

"""Two new dataframes are then created containing the scaled values of the original data. This is done so that the scaled data have the same column names as the original dataframes. It is preprocessing to ensure that both accuracy scores of the data before and after scaling can be produced."""

logistic_x_train_scaled = pd.DataFrame(logistic_x_train_scaled, columns=logistic_x_train.columns)
logistic_x_test_scaled = pd.DataFrame(logistic_x_test_scaled, columns=logistic_x_test.columns)

"""I then wanted to see the accuracy of the logistic regression model. I compared the accuracy of the model before and after scaling."""

#@title Accuracy of logistic regression modelling
logreg = LogisticRegression()
logreg.fit(logistic_x_train_scaled, logistic_y_train)


logistic_y_pred_before = logreg.predict(logistic_x_test)
logistic_y_pred_after = logreg.predict(logistic_x_test_scaled)

logistic_accuracy_before = accuracy_score(logistic_y_test, logistic_y_pred_before)
logistic_accuracy_after = accuracy_score(logistic_y_test, logistic_y_pred_after)

print("Accuracy before scaling:", logistic_accuracy_before)
print("Accuracy after scaling:", logistic_accuracy_after)

"""With an accuracy score of 91.83%, it is evident that the FFMC, ISI and FWI are all very important features when it comes to predicting the occurence of a forest fire. However, I believe that other models would be better suited for the prediction, and would grant higher results.

Despite this, the accuracy before and after scaling has a significant difference here. This is because, since the features have such difference scales, the model will have biases toward the features with larger scales. This is why scaling the data is so important because it removes bias from the larger features, such as the Drought Code.

### *Decision Tree Modelling - Impact of the main features on the target*

I decided to investigate some of the questions I had using a Decision Tree Model. I wanted to compare the difference between the accuracy of the prediction using a logistic regression model, and a decision tree model. I would keep the independant and dependant variables the same, whilst applying the different models to see the difference in accuracies.

I have made 2 models here with varying accuracy to study the effects of important variables such as the fire weather index, when it comes to predicting a forest fire.

**Train Test Split**

In order to create a decision tree, just like with the regression models, I needed to create a train-test split. I created one of the same size to ensure that comparing the models would be as accurate as possible when determining the best one.
"""

attribute_frame = logistic_dataframe.drop(["Target"], axis=1)
output_frame = logistic_dataframe[["Target"]]
attribute_train, attribute_test, output_train, output_test = train_test_split(attribute_frame, output_frame, test_size=0.25, random_state=25)

"""**Scaling**

I then scaled the data as before, I wanted to compare the difference between the scaled data and unscaled data.
"""

attribute_train_scaled, attribute_test_scaled = standard_scaler(attribute_train, attribute_test)

"""I then created a Decision Tree Classifier model to fit my scaled data into. I printed a visualised tree for visualisation purposes."""

#@title First Decision Tree Model
decision_tree_mf = DecisionTreeClassifier()
decision_tree_mf.fit(attribute_train_scaled, output_train)

visualised_tree = export_text(decision_tree_mf, feature_names=["FFMC", "ISI", "FWI"])
print(visualised_tree)

"""I then wanted to see the accuracy of my Decision Tree model. I wanted to analyse how the FFMC, ISI and FWI could accurately predict the occurence of a forest fire, as these were the most important features that I gathered from the data analysis."""

#@title Accuracy score
decision_tree_mf_prediction = decision_tree_mf.predict(attribute_test.values)
decision_tree_mf_accuracy = accuracy_score(output_test, decision_tree_mf_prediction)

decision_tree_mf_prediction_scaled = decision_tree_mf.predict(attribute_test_scaled)
decision_tree_mf_accuracy_scaled = accuracy_score(output_test, decision_tree_mf_prediction_scaled)

print("Accuracy before scaling:", decision_tree_mf_accuracy)
print("Accuracy after scaling:", decision_tree_mf_accuracy_scaled)

"""The accuracy score on the 3 features alone was 98.36%. This is a very impressive score which confirms the importance of these features.

Furthermore, in comparison with the logistic regression model whilst using the same dataset, the decision tree classifier model has granted a much higher accuracy, (98.36% opposed to 91.83%) which is why I believe it is a much more effective model when analysing the occurence and absence of forest fires.

I believe this model was better than the logistic regression model because a decision tree model is able to identify the most important features for predicting a forest fire, which is critical in these circumstances. Although logistic regression is also good at identifying important features, it may not have been able to capture the more complex interactions between the variables, and how it contributes to the target.

Scaling the data has proven its effectiveness with the accuracy score results. As you can see, there is a very large difference in the dataset:


"""

#@title Variance in the dataset
logistic_dataframe.describe()

"""Which emphasizes the importance of scaling yet again, as it minimises the differences between the features.

To find out the importance of the FWI and the features that apply to it, I wanted to see how the predictions would change if important variables such as the FWI and the FFMC were removed.

### *Decision Tree Modelling - Impact on the target without the main features*

I have created a new dataframe based on the original this time, but removed the features previously tested (the FWI, FFMC and ISI). This was to analyse how the accuracy of the model would change without these features. Since they were used to accurately predict the target, I felt that it was important to see how a decision tree model could accurately predict a forest fire if these features had no involvement.

**Train-Test Split**

To begin with I created a train-test Split.
"""

df_noFWI = df1.drop(["FWI", "FFMC", "ISI"], axis=1)
x_noFWI = df_noFWI.drop(["Target"], axis=1)
y_noFWI = df_noFWI[["Target"]]
x_train_noFWI, x_test_noFWI, y_train_noFWI, y_test_noFWI = train_test_split(x_noFWI, y_noFWI, test_size=0.25, random_state=25)

"""**Scaling the Data**

The data was then scaled.
"""

x_train_noFWI_scaled, x_test_noFWI_scaled = standard_scaler(x_train_noFWI, x_test_noFWI)

"""**Fiting the Decision Tree Model on the dataset**

I then fitted the model, and printed the visualisation.
"""

#@title Second Decision Tree Model
dt_noFWI = DecisionTreeClassifier()
dt_noFWI.fit(x_train_noFWI_scaled, y_train_noFWI)
dt_noFWI_pred = dt_noFWI.predict(x_test_noFWI_scaled)

visualised_tree2 = export_text(dt_noFWI, feature_names=["Temp", "RH", "Ws", "Rain", "DMC", "DC", "BUI"])
print(visualised_tree2)

#@title Accuracy score
second_tree_accuracy_prediction = dt_noFWI.predict(x_test_noFWI.values)
second_tree_accuracy = accuracy_score(y_test_noFWI, second_tree_accuracy_prediction)
print("Accuracy before scaling:", second_tree_accuracy)

second_tree_accuracy_prediction_scaled = dt_noFWI.predict(x_test_noFWI_scaled)
second_tree_accuracy_scaled = accuracy_score(y_test_noFWI, second_tree_accuracy_prediction_scaled)
print("Accuracy after scaling:", second_tree_accuracy_scaled)

"""As you can see, the accuracy percentage dropped to 91.80%. I was surprised to find the accuracy was still high, but it goes to show the effectiveness of the Decision Tree Model in itself.

### *Decision Tree Modelling - Impact of temperature on the target*

To answer a previous question I had, I decided to do a small test on the effectiveness of the temperature on predicting a forest fire. I decided on using a decision tree model as it has proven to be highly effective.

**Train-Test Split**
"""

dataframe_with_temperature = df1.drop(["RH", "Ws", "Rain", "FFMC", "DMC", "DC", "ISI", "BUI", "FWI"], axis=1)
temperature_frame = dataframe_with_temperature[["Temp"]]
temperature_output_frame = dataframe_with_temperature[["Target"]]

temp_train, temp_test, temp_output_train, temp_output_test = train_test_split(temperature_frame, temperature_output_frame, test_size=0.25, random_state=25)

"""**Scaling the data**"""

temp_train_scaled, temp_test_scaled = standard_scaler(temp_train, temp_test)

"""**Fitting the Decision Tree Model**"""

temp_tree = DecisionTreeClassifier()
temp_tree.fit(temp_train_scaled, temp_output_train);

#@title Accuracy score
temp_tree_prediction_scaled = temp_tree.predict(temp_test_scaled)
temp_tree_accuracy_scaled = accuracy_score(temp_output_test, temp_tree_prediction_scaled)
print("Accuracy after scaling:", temp_tree_accuracy_scaled)

"""Since I was only using one independant variable, I did not test the difference of the accuracy result before and after scaling, because there wouldn't be any.

Using a Decision Tree Classifier model on the Temperature granted a 72.13% accuracy score for predicting a forest fire. This is expected, because temperature would never be able to accurately predict a forest fire on its own. In other words, a certain temperature does not grant the occurence of a forest fire, as there will be some days with hotter temperatures without a fire, and other days that have lower temperatures and a forest fire occurs.

## **Evaluation**

It is evident based on the accuracy scores that the decision tree classifier model is much more beneficial over the logistic regression model, despite both yielding high accuracies.

The linear regression model was effective at analysing how the features could predict the fire wind index, which, once we know the FWI, we could then be able to accurately predict the occurence of a fire itself. However, although this regression model was deemed effective, it can not directly be used to predict the occurence of a fire, so I wouldn't recommend for it to be used if there are other means to gather the fire weather index.

To further my evaluation, I have gathered the answers to the following questions I previously had:


*   How do the environmental features correlate to the Fire Weather Index? - Using the linear regression model, it is evident that they share a high correlation with one another.
*   How accurately could the temperature change predict a forest fire? - With an accuracy score of 72.13%, it is a very inneffective way at predicting a forest fire.
*   How much of an impact do the FFMC, ISI and FWI have on the target outcome? - A very large impact, I would say they are the most important features of the recorded data, as the three of them alone yielded a 98.36% accuracy.
*   Since the FWI was made specifically to predict a forest fire, how would our accuracy change without it? - Removing the important features decreased the accuracy by around 7%, which, although I thought would be more significant, proves the effectiveness of the decision tree classifier model
*   How does scaling the data effect the models? - It has a much larger impact on the classification based models because it can cause biases in the data when trying to deem the accuracy of a model.

---

# **4. Discussion of results**

I will now be discussing the results I discovered during the creation of the various models.

I've formatted the acquired results into a table:

<table>
  <tr>
    <th> Model </th>
    <th> Effectiveness </th>
    <th> Main Test? </th>
  </tr>
  <tr>
    <td>Linear Regression</td>
    <td>93.38%</td>
    <td>Y</td>
  </tr>
  <tr>
    <td>Logistic Regression</td>
    <td>91.83%</td>
    <td>Y</td>
  <tr>
    <td>Decision Tree Classification with important features</td>
    <td>91.83%</td>
    <td>Y</td>
  </tr>
  <tr>
    <td>Decision Tree Classification without important features</td>
    <td>91.80</td>
    <td>N</td>
  </tr>
    <tr>
    <td>Decision Tree Classification using Temperature</td>
    <td>72.13%</td>
    <td>N</td>
  </tr>

Looking at the table, it is evident that, based on the main tests, the Decision Tree Classifier model has proved to be the most effective of the different models. It scored slightly higher than the linear and logistic regression models, which is why it would be the most effective model out of the three when testing for the potential occurence of a forest fire.

Having said that, as mentioned previously, linear regression is a model that is tested on the Fire Weather Index as opposed to the target, so it cannot be compared to the classification models.

The table also shows the effectiveness of the other two Decision Tree tests, that were not main tests involved in my analysis, rather they were used to answer some questions I had. It is evident that the temperature should never be an accurate predictor for a forest fire, and that the Fire Weather Index (FWI), the Fine Fuel Moisture Code (FFMC) and the Initial Spread Index (ISI) are all very important factors that should be considered when predicting a forest fire.

**Confusion Matrices**

A confusion matrix is a machine learning method that allows us to measure the precision and accuracy of a data model. In this case, I will be creating Confusion Matrices on the Logistic Regression model and the Decision Tree Classifier model.

*Linear regression*

Since linear regression bases its prediction on continuous numerical values, a classification based model like a confusion matrix can not be made on it.

Despite this, I have clustered the data using a KMeans model to explore the relationships and groupings within the data.
"""

#@title Clustering the data
k_model = KMeans(n_clusters=2, init="random", n_init=1)
k_fitted_model = k_model.fit(x_train_scaled)
y_prediction = k_fitted_model.predict(x_test_scaled)
print(y_prediction)

"""Clustering the data could  help to identify different types of conditions that are associated with a fire. In this example, I wanted to see how the conditions are associated with the Fire Weather Index."""

#@title Gathering a silhouette score based on the clustered data
dataset_silhouette = silhouette_score(x_test_scaled, y_prediction)
print(dataset_silhouette)

"""Based on the results, it appears that clustering the data has deemed itself ineffective in this scenario, only reaching a score of 36.09%. I would suspect this is due to features such as the rain and humidity, which could be obscuring the data as they had a negative correlation with the fire weather index.

*Logistic regression*

I created a confusion matrix on my logistic regression model to represent the prediction summary in matrix form. It is used to show how many predictions are correct and incorrect per class.
"""

#@title Logistic Confusion Matrix
logistic_matrix = confusion_matrix(logistic_y_test, logistic_y_pred_after)
logistic_disp = ConfusionMatrixDisplay(confusion_matrix=logistic_matrix)
logistic_disp.plot()
plt.title("Logistic Regression Confusion Matrix (After Scaling)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.grid(False)
plt.show()

print(accuracy_score(logistic_y_test, logistic_y_pred_after))

"""In the confusion matrix:

*   Top Left Box - Represents the number of true negatives that have been correctly predicted. This model correctly predicted all 17 outcomes where the result was "no fire".
*   Top Right Box - Represents the number of false positives, where the model predicted a positive outcome, but the actual outcome was negative. It did not predict "fire" when the outcome was "no fire", as the result is 0.
*   Bottom Left Box - Represents the number of false negatives, which is where the model predicted "no fire", but the actual outcome was "fire". The score for this is 4, meaning the model missed 4 cases that were actually a fire. This could be detrimental in some cases.
*   Bottom Right Box - Represents the number of true positives, representing the number of accurately predicted fires, meaning the model correctly predicted "fire" for 28 cases.

*Decision Tree Classification*

I then created a confusion matrix for my decision tree classification model to identify and compare the differences between the effectiveness of both models.
"""

#@title Decision Tree Confusion Matrix
y_array = np.array(output_test)
y_pred = decision_tree_mf.predict(attribute_test_scaled)
dtc_matrix = confusion_matrix(output_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=dtc_matrix)
disp.plot()
plt.title("Decision Tree Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.grid(False)
plt.show()

print(accuracy_score(y_array, y_pred))

"""Evidently based on the model, the results are much more accurate than the logistic regression model, which is why such a model is sub-efficacious in this scenario.

The model shows that there was only one case where the model predicted no fire when there was one, which is, in my opinion, a detrimental difference because it could create a huge difference in fire prevention.

When comparing the Decision Tree model to the Logistic Regression model, for the decision tree, there was only one wrong outcome, as opposed to four wrong outcomes for the logistic regression model.

In the real world, 1 incorrectly predicted fire as opposed to 4 is a monumental improvement, hence why I believe that the Decision Tree model should be utilised over the other models tested when analysing forest fire data.

In my opinion, I believe that one of the reasons that the Decision Tree Model has been proven to be more effective than the Logistic Regression model is because the logistic regression model is sensitive to outliers. Since I did think that it was necessary to remove outliers after scaling the data, it could have been the reason as to why the logistic regression model wasn't as effective. Had an IQR or Z-Score method been carried out on the data as part of the pre-processing, I believe that the score's would be much more similar. The Decision Tree model tends to be robust in most cases when it comes to handling outliers without creating splits that can isolate them.

In the future, I think all of the accuracy scores for each model could be improved by applying outlier removal techniques, such as the Z-score technique, because removing outliers would allow for much better predictions as the data is not skewed by values that are far out of range.

# **5. Conclusion**

To conclude, my results show that classification techniques are the most useful modelling techniques for forest fire analysis. This is because the target output is either "no fire" or "fire", which can be represented in binary as 0 or 1.

The most accurate classification technique based on the models I created was the Decision Tree classifier model. I believe that it was better suited for the dataset over logistic regression modelling because it is not as sensitive to outliers, and it is a more robust model. In general, both methods provided accuracy scores of over 90%, which is very effective, although I believe the scores could be increased with the removal of outliers.

I believe that, with further analysis, I could've constructed more models on the dataset to provide a more in depth comparison between them, thus allowing me to determine the best classification model, as opposed to just comparing two. Although the Decision tree classifier presented a very good accuracy score, other models may have produced even better results had they been tested on the data, so therefore it is impossible to determine whether or not the decision tree classifier accuracy was the best accuracy achieveable.

Although removing outliers and training more models on the data may grant greater accuracies, every model has their advantages and disadvantages, so as much as we'd like to get an accuracy score of 100% to be able to predict a forest fire accurately all of the time without fail, it would be impossible to do so due to the variance in our data even after scaling.

Additionally, the linear regression model was able to determine the strong linear correlation of the main features with the Fire Weather Index, which underlined their importance, hence why they are all taken into the account to give an accurate FWI reading.

However, it is, and always will be almost impossible to predict when and where a forest fire will occur, considering that the majority of them are caused by humans and lightning. The data presented only gives us an insight into the forest fire itself, now how it started, but this doesn't mean to say we can't get a general idea.

**Positives and Negatives of each model?**

<table>
  <tr>
    <th> Model </th>
    <th> Advantages </th>
    <th> Disadvantages </th>
  </tr>
  <tr>
    <td>Linear Regression</td>
    <td>Works well with linearly related variables, very interpretable</td>
    <td>Very sensitive to outliers and it is assumed that the correlation between dependant and independant variables is linear</td>
  </tr>
  <tr>
    <td>Logistic Regression</td>
    <td>Easy to interpret and provide a probabilistic output rather than just a prediction</td>
    <td>Sensitive to outliers, and is limited to binary classification</td>
  <tr>
    <td>Decision Tree Classification</td>
    <td>Easy to interpret, easily scalable and is able to handle categorial and numerical data</td>
    <td>Bias toward larger features without scaling</td>
  </tr>

# **6. References**

The references I have used are:

https://en.wikipedia.org/wiki/Forest_fire_weather_index

https://github.com/aravind-selvam/forest-fire-prediction/blob/main/notebook/Forest%20Fire%20Part-2%20Model.ipynb

https://www.simplilearn.com/what-is-data-standardization-article#:~:text=Data%20standardization%20is%20converting%20data,YYYY%2DMM%2DDD).

https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202#:~:text=Principal%20component%20analysis%20(PCA)%20is,variables%20that%20successively%20maximize%20variance.

https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/what-is-linear-regression/

https://www.saedsayad.com/decision_tree_reg.htm

https://www.shiksha.com/online-courses/articles/train-test-split/

https://www.investopedia.com/terms/r/r-squared.asp

https://h2o.ai/wiki/confusion-matrix/#:~:text=A%20confusion%20matrix%20is%20a,which%20the%20data%20originally%20belonged.

https://www.sciencedirect.com/topics/engineering/confusion-matrix#:~:text=A%20confusion%20matrix%20represents%20the,by%20model%20as%20other%20class.

https://www.edureka.co/blog/linear-regression-for-machine-learning/

https://climate-adapt.eea.europa.eu/en/metadata/indicators/fire-weather-index-monthly-mean-1979-2019#:~:text=The%20FWI%20uses%20information%20about,amount%20of%20fuel%20being%20consumed.

https://cwfis.cfs.nrcan.gc.ca/background/summary/fwi?wbdisable=true#:~:text=The%20Fine%20Fuel%20Moisture%20Code,the%20flammability%20of%20fine%20fuel.

https://daac.ornl.gov/CMS/guides/CMS_Fire_Weather_Data_AK.html

https://cwfis.cfs.nrcan.gc.ca/background/summary/fwi#:~:text=The%20Buildup%20Index%20(BUI)%20is,down%20in%20the%20available%20fuel.

https://www.bbc.com/future/article/20180924-the-quest-to-predict-and-stop-the-spread-of-wildfires#:~:text=Most%20of%20all%2C%20given%20that,can't%20get%20an%20idea.

https://www.bankrate.com/insurance/homeowners-insurance/wildfire-statistics/#:~:text=Between%202021%2D2022%2C%20wildfires%20accounted,damage%20across%20the%20United%20States.
"""